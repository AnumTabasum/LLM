# -*- coding: utf-8 -*-
"""LLM1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rytK26uVMOc00benBnRIRFlV_j7cGVZY
"""

#Sentiment anaylsis
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F

# Load tokenizer and model
tokenizer = AutoTokenizer.from_pretrained(
    "distilbert-base-uncased-finetuned-sst-2-english"
)
model = AutoModelForSequenceClassification.from_pretrained(
    "distilbert-base-uncased-finetuned-sst-2-english"
)

# User input
sentence = input("Enter a sentence: ")

# Tokenize input
inputs = tokenizer(sentence, return_tensors="pt")

# Model inference
with torch.no_grad():
    outputs = model(**inputs)

# Apply softmax to get probabilities
probs = F.softmax(outputs.logits, dim=1)

# Get prediction and confidence
confidence, predicted_class = torch.max(probs, dim=1)

# Display result
sentiment = "POSITIVE" if predicted_class.item() == 1 else "NEGATIVE"
print("Sentiment:", sentiment)
print("Confidence Score:", round(confidence.item(), 2))

